{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For turing users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install discrete-optimization-extension --extra-index-url https://pip.dsrg.fh-zwickau.de\n",
    "# !pip install bias-variance-agent=='0.1.0.dev1' --extra-index-url https://pip.dsrg.fh-zwickau.de\n",
    "# !pip install imblearn\n",
    "# !pip install jutils with pip install --extra-index-url https://pip.dsrg.fh-zwickau.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, SCORERS\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import biva\n",
    "import dope\n",
    "from biva.agent import Agent, Mode\n",
    "\n",
    "# https://doc.dsrg.fh-zwickau.de/jutils/devel/\n",
    "from jutils.plot import Plot\n",
    "from jutils.html import HBox\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biva.utils import check_gpu, check_tf_version, set_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.3.1\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_tf_version()\n",
    "check_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0x17a5ab1b370>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_gpu(per_process_gpu_memory_fraction=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"content\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Data](#data)\n",
    "* [Data preprocessing](#data_preprocess)\n",
    "* [General principle](#general)\n",
    "* [Usage](#usage)\n",
    "    * [Define Agent](#definition)\n",
    "    * [Define config](#config)\n",
    "    * [Train](#train)\n",
    "    * [Optimize](#optimize)\n",
    "* [Features](#features)\n",
    "    * [Data partitions](#data_partitions)\n",
    "    * [Customize fit](#fit)\n",
    "    * [Preprocessing optimization](#preprocessing)\n",
    "    * [Custom evaluation](#evaluation)\n",
    "    * [Customize scan](#Customize)\n",
    "* [Examples](#examples)\n",
    "* [Unbalanced data](#Unbalanced_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"install\"></a>\n",
    "## [Data](#content) \n",
    "\n",
    "<font color=green> **The classification goal is to predict if the client will subscribe (yes/no) a term deposit (variable y).**</font>\n",
    "\n",
    "The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y).\n",
    "\n",
    "\n",
    "\n",
    "**Data Set Information:**\n",
    "\n",
    "You will find the data in `data/bank-full.csv`. \n",
    "\n",
    "The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed.\n",
    "\n",
    "**Attribute Information:**\n",
    "\n",
    "`Input variables:`\n",
    "#### bank client data:\n",
    "+ 1 - age (numeric)\n",
    "+ 2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "+ 3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "+ 4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "+ 5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "+ 6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "+ 7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "\n",
    "#### related with the last contact of the current campaign:\n",
    "\n",
    "+ 8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "+ 9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "+ 10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "+ 11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "####  other attributes:\n",
    "+ 12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "+ 13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "+ 14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "+ 15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "\n",
    "#### social and economic context attributes\n",
    "\n",
    "+ 16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "+ 17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "+ 18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "+ 19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "+ 20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "#### Output variable (desired target):\n",
    "\n",
    "+ 21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_preprocess\"></a>\n",
    "## [Data preprocessing](#content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biva.utils import get_categorical_cols, get_numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorical cols: ['month', 'housing', 'y', 'default', 'contact', 'job', 'education', 'marital', 'loan', 'poutcome', 'day']\n",
      "  numerical cols: ['age', 'balance', 'duration', 'campaign', 'pdays', 'previous']\n"
     ]
    }
   ],
   "source": [
    "RND_SEED = 0\n",
    "data = pd.read_csv('../../data/bank-full.csv', sep= ';')\n",
    "# data = pd.read_csv('../datasets/lecture/bank-full.csv', sep= ';')\n",
    "# data = pd.read_csv('../datasets/lecture/bank-additional-full.csv', sep=';')\n",
    "\n",
    "# Datatype changes\n",
    "data['day'] = data['day'].astype(str)\n",
    "\n",
    "categorical = get_categorical_cols(data)\n",
    "numerical = get_numerical_cols(data)\n",
    "print(f'categorical cols: {categorical}')\n",
    "print(f'  numerical cols: {numerical}')\n",
    "\n",
    "# Encoding the variables\n",
    "label_encoder = defaultdict(LabelEncoder)\n",
    "std_scaler = StandardScaler()\n",
    "mm_scaler = MinMaxScaler()\n",
    "\n",
    "df = data.copy()\n",
    "df[categorical] = data[categorical].apply(lambda x: label_encoder[x.name].fit_transform(x))\n",
    "df[numerical] = mm_scaler.fit_transform(df[numerical])\n",
    "df[\"balance\"] = std_scaler.fit_transform(df[[\"balance\"]])\n",
    "\n",
    "categorical.remove('y')\n",
    "\n",
    "X = df.drop(\"y\", 1)\n",
    "y = df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.519481</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.256419</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>0.053070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.337662</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.437895</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>0.030704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.194805</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.446762</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>0.015453</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.376623</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>0.018707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194805</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.447091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>0.040260</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  job  marital  education  default   balance  housing  loan  \\\n",
       "0  0.519481    4        1          2        0  0.256419        1     0   \n",
       "1  0.337662    9        2          1        0 -0.437895        1     0   \n",
       "2  0.194805    2        1          1        0 -0.446762        1     1   \n",
       "3  0.376623    1        1          3        0  0.047205        1     0   \n",
       "4  0.194805   11        2          3        0 -0.447091        0     0   \n",
       "\n",
       "   contact  day  month  duration  campaign  pdays  previous  poutcome  y  \n",
       "0        2   26      8  0.053070       0.0    0.0       0.0         3  0  \n",
       "1        2   26      8  0.030704       0.0    0.0       0.0         3  0  \n",
       "2        2   26      8  0.015453       0.0    0.0       0.0         3  0  \n",
       "3        2   26      8  0.018707       0.0    0.0       0.0         3  0  \n",
       "4        2   26      8  0.040260       0.0    0.0       0.0         3  0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"general\"></a>\n",
    "# [General principle](#content) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from biva.agent import Agent\n",
    "\n",
    "def build_model(config):\n",
    "    # ... Model creation using dictionary with hyperparams config \n",
    "    return model\n",
    "\n",
    "def fit_func(model, config, x_train, y_train, validation_data, **kwargs):\n",
    "    # config - optimizible hyperparams\n",
    "    # kwargs - other attrs for fit passed from train_model_on, optional\n",
    "    result = model.fit(x_train, y_train, validation_data, attr1=config['attr1'], attr2=kwargs['attr2'])\n",
    "    bias, variance = result['bias'], result['variance']\n",
    "    return bias, variance\n",
    "    \n",
    "def preprocess(config, *data):\n",
    "    # X and Y variables retrieval\n",
    "    # Preprocessing steps with optimizible params like different thresholds for outlier detection ect.\n",
    "    x, y = df.drop(\"y\", 1), df.y\n",
    "    return x, y\n",
    "\n",
    "# Instantiate object and off we go\n",
    "agnt = Agent(X, Y, preprocessing=preprocess, build_model=build_model, fit_func=fit_func)\n",
    "\n",
    "# train model\n",
    "agnt.train_model_on(**kwargs)\n",
    "\n",
    "# optimize\n",
    "agnt.scan('acs', **kwargs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"usage\"></a>\n",
    "# [1. Usage](#content) \n",
    "\n",
    "#### XGB example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biva.agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "    \n",
    "def build_model_xgb(config):\n",
    "    model = XGBClassifier(**config, random_state=RND_SEED, verbosity=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"definition\"></a>\n",
    "## [1.1 Define Agent](#content) with `build_model` attibute and data.\n",
    "\n",
    "In case of sklearn models and simple keras models this is pretty much everything we need to get going.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agnt_xgb = Agent(X, y, build_model=build_model_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"config\"></a>\n",
    "## [1.2 Define config](#content) dictionary that cointains hyperparameters of our model.\n",
    "\n",
    "`config` is always passed to `build_model` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_xgb = {\n",
    "    'objective': 'binary:logistic', 'tree_method':'gpu_hist', 'use_label_encoder': False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train\"></a>\n",
    "## [1.3 Train](#content) \n",
    "\n",
    "***train_model_on*** method is used to train and validate model on specific data partitions. <br>\n",
    "It can be used to train model using certain model `config` to see the effect of different hyperparameters on performance or just to estimate current performance. <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 40689 samples, testing on 4522 samples.\n",
      "\u001b[36mTraining session: 1  | loss: 9.5313e-01 | val_loss: 9.0226e-01**\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "result, model = agnt_xgb.train_model_on(config_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"optimize\"></a>\n",
    "## [1.4 Optimize](#content) with *scan*\n",
    "\n",
    "**1) Define parameter space using ```dope.Mode```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'n_estimators' : [50, 200] (2), \n",
      "'gamma'        : [0, 1] (2), \n",
      "'subsample'    : [0.    0.125 0.25  0.375 0.5   0.625 0.75  0.875 1.   ] (9)\n",
      "Total number of grid cofigurations: 3.60e+01 | 36\n",
      "Total number of acs  cofigurations: 1.30e+01 | 13\n"
     ]
    }
   ],
   "source": [
    "from dope.method import Mode\n",
    "from biva.utils import format_parameter_space\n",
    "\n",
    "subsample = np.linspace(0, 1, 9)\n",
    "params = [\n",
    "    Mode('n_estimators', values=[50, 200], mode_optimizer=\"gridsearch\"),\n",
    "    Mode('gamma',        values=[0, 1],    mode_optimizer=\"bayessearch\"),\n",
    "    Mode('subsample',    values=subsample, mode_optimizer=\"randomsearch\", random_samples=2),\n",
    "]\n",
    "\n",
    "print(format_parameter_space(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Call ```Agent().scan()``` and specify search type `optimizer` of your choice.**\n",
    "\n",
    "Different optimizers require specific arguments, but error message will let you know if somethibng is missing. For more info see `scan` and `dope` docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"iterations\" positional argument is missing. Using default value: 1\n",
      "\"order\" positional argument is missing. Using default order: ['n_estimators', 'gamma', 'subsample']\n",
      "\n",
      "acs\n",
      "# Iteration: 1\n",
      "\n",
      "GridSearch for Hyperparameter: n_estimators\n",
      "Current configuration: {'objective': 'binary:logistic', 'tree_method': 'gpu_hist', 'use_label_encoder': False, 'n_estimators': 50, 'gamma': 0, 'subsample': 0.000000e+00}\n",
      " Variance: -8.834574e-01, Bias: -8.834574e-01, HyperParams: {'n_estimators': 50}, Time: 0:00:01\n",
      " Variance: -8.834575e-01, Bias: -8.834574e-01, HyperParams: {'n_estimators': 200}, Time: 0:00:03\n",
      "Max. Variance: -8.834575e-01, Best HyperParams: {'n_estimators': 200}, Time: 0:00:05\n",
      "\n",
      "BayesSearch for Hyperparameter: gamma\n",
      "Current configuration: {'objective': 'binary:logistic', 'tree_method': 'gpu_hist', 'use_label_encoder': False, 'n_estimators': 200, 'gamma': 0, 'subsample': 0.000000e+00}\n",
      " Variance: -8.834574e-01, Bias: -8.834574e-01, HyperParams: {'gamma': 4.750015e-01}, Time: 0:00:03\n",
      " Variance: -8.834574e-01, Bias: -8.834574e-01, HyperParams: {'gamma': 5.825053e-01}, Time: 0:00:04\n",
      " Variance: -8.834573e-01, Bias: -8.834574e-01, HyperParams: {'gamma': 6.415514e-01}, Time: 0:00:04\n",
      " Variance: -8.834573e-01, Bias: -8.834574e-01, HyperParams: {'gamma': 4.682844e-01}, Time: 0:00:05\n",
      " Variance: -8.834574e-01, Bias: -8.834574e-01, HyperParams: {'gamma': 4.750179e-01}, Time: 0:00:04\n",
      " Variance: -8.834574e-01, Bias: -8.834574e-01, HyperParams: {'gamma': 4.747002e-01}, Time: 0:00:05\n",
      " Variance: -8.834574e-01, Bias: -8.834574e-01, HyperParams: {'gamma': 4.743221e-01}, Time: 0:00:05\n",
      " Variance: -8.834574e-01, Bias: -8.834574e-01, HyperParams: {'gamma': 2.775910e-01}, Time: 0:00:06\n",
      "Max. Variance: -8.834574e-01, Best HyperParams: {'gamma': 2.775910e-01}, Time: 0:00:39\n",
      "\n",
      "RandomSearch for Hyperparameter: subsample\n",
      "Current configuration: {'objective': 'binary:logistic', 'tree_method': 'gpu_hist', 'use_label_encoder': False, 'n_estimators': 200, 'gamma': 2.775910e-01, 'subsample': 0.000000e+00}\n",
      " Variance: -8.899458e-01, Bias: -9.321930e-01, HyperParams: {'subsample': 0.125}, Time: 0:00:39\n",
      " Variance: -9.022094e-01, Bias: -9.769778e-01, HyperParams: {'subsample': 0.5}, Time: 0:00:59\n",
      "Max. Variance: -9.022094e-01, Best HyperParams: {'subsample': 0.5}, Time: 0:01:39\n",
      "\n",
      "Best config: {'objective': 'binary:logistic', 'tree_method': 'gpu_hist', 'use_label_encoder': False, 'n_estimators': 200, 'gamma': 0.27759103997163737, 'subsample': 0.5}\n",
      "time elapsed: 0:02:24\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "variance, bconf, model = agnt_xgb.scan('acs', parameter_space=params, config=config_xgb, strategy='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bconf` contains your best hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"features\"></a>\n",
    "# [2. Features](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_partitions\"></a>\n",
    "##  2.1 You can use different [data partitions](#content) for training and scanning\n",
    "\n",
    "by specifying `training_mode` or `evaluation_mode` argument.\n",
    "\n",
    "<br>\n",
    "<img src=\"../images/data_partitions.png\" alt=\"Data partitions\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Data partition attributes:***\n",
    "\n",
    "    train_data: Train data. Usually 80-90% of entire data.\n",
    "                Used to train or evaluate model.\n",
    "    train_y:    Train target data. (Might not be present)\n",
    "    train_xy:   a tuple (train_data, train_y)\n",
    "\n",
    "    test_data:  Test data. Data that model has never seen during training.\n",
    "                Used for final model testing.\n",
    "    test_y:     Test target data.\n",
    "    test_xy:    a tuple (test_data, test_y)\n",
    "    \n",
    "    \n",
    "    val_train_data:  Train data. 80-90% of train_data.\n",
    "    val_train_y:     Train target data. 80-90% of train_y.\n",
    "    val_train_xy:    a tuple (val_train_data, val_train_y)\n",
    "\n",
    "    val_data:  Validation data. 10-20%(val_split) of train_data.\n",
    "    val_y:     Validation target data. 10-20% of train_y.\n",
    "    val_xy:    a tuple (val_data, val_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Final model performance can be obtained by calling train model on the full data using ```training_mode='full'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 45211 samples.\n",
      "\u001b[36mTraining session: 1  | loss: 9.6627e-01**\n",
      "\u001b[0mTraining on 40689 samples, testing on 4522 samples.\n",
      "\u001b[36mTraining session: 1  | loss: 9.7100e-01 | val_loss: 8.9142e-01**\n",
      "\u001b[0mTraining on 36620 samples, testing on 4069 samples.\n",
      "\u001b[36mTraining session: 1  | loss: 9.7179e-01 | val_loss: 9.6510e-01**\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "res, model = agnt_xgb.train_model_on(config_xgb, data_partitions='full')\n",
    "res, model = agnt_xgb.train_model_on(config_xgb, data_partitions='test')\n",
    "res, model = agnt_xgb.train_model_on(config_xgb, data_partitions='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias: 9.770e-01, var: 9.010e-01\n",
      "bias: 9.765e-01, var: 9.020e-01\n",
      "bias: 9.764e-01, var: 9.019e-01\n"
     ]
    }
   ],
   "source": [
    "bias, var, model = agnt_xgb.eval_func(config_xgb, evaluation_mode='full')\n",
    "print(f'bias: {bias:.3e}, var: {var:.3e}')\n",
    "\n",
    "bias, var, model = agnt_xgb.eval_func(config_xgb, evaluation_mode='test')\n",
    "print(f'bias: {bias:.3e}, var: {var:.3e}')\n",
    "\n",
    "bias, var, model = agnt_xgb.eval_func(config_xgb, evaluation_mode='val')\n",
    "print(f'bias: {bias:.3e}, var: {var:.3e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fit\"></a>\n",
    "## 2.2 Customize [fit](#content)  function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_(true, pred, thresh=5/7):\n",
    "    pred_label = np.where(pred > 5/7, 1, 0)  \n",
    "    loss = np.int16((true==1)&(pred_label==0)) * 5 * (1 - pred)\\\n",
    "        + np.int16((true==0)&(pred_label==1)) * 25 * pred\\\n",
    "        + np.int16((true==1)&(pred_label==1)) * (-5) * pred\n",
    "    return np.sum(loss)\n",
    "\n",
    "def get_loss(model, data, thresh=5/7):\n",
    "    y_pred = model.predict_proba(data[0])[:, 1]\n",
    "    return loss_(data[1], y_pred)\n",
    "\n",
    "# Fit function must take following arguments and return a tuple (bias, variance)\n",
    "def fit(model, config, train_data, test_data, **kwargs):\n",
    "    try:\n",
    "        model.fit(*train_data)\n",
    "    except ValueError:\n",
    "        return np.inf, np.inf\n",
    "    \n",
    "    loss = get_loss(model, train_data)\n",
    "    if test_data is not None:\n",
    "        val_loss = get_loss(model, test_data)\n",
    "        return loss, val_loss\n",
    "    else:\n",
    "        return loss, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 40689 samples, testing on 4522 samples.\n",
      "\u001b[36mTraining session: 1  | loss: -5.9273e+03 | val_loss: 2.1971e+03**\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "agnt_xgb = Agent(X, y, build_model=build_model_xgb, fit_func=fit)\n",
    "result, model = agnt_xgb.train_model_on(config_xgb, data_partitions='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"preprocessing\"></a>\n",
    "## 2.3 Optimize parameters for [preprocessing step](#content)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"height:20em;column-gap:1em;display:flex;flex-direction:row;flex-shrink:0;overflow-x:auto;white-space:nowrap;\"><img style=\"margin-top:unset;\" src=\"data:image/svg+xml;utf-8,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22utf-8%22%20standalone%3D%22no%22%3F%3E%0A%3C%21DOCTYPE%20svg%20PUBLIC%20%22-//W3C//DTD%20SVG%201.1//EN%22%0A%20%20%22http%3A//www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd%22%3E%0A%3C%21--%20Created%20with%20matplotlib%20%28https%3A//matplotlib.org/%29%20--%3E%0A%3Csvg%20height%3D%22249.23625pt%22%20version%3D%221.1%22%20viewBox%3D%220%200%20367.25%20249.23625%22%20width%3D%22367.25pt%22%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20xmlns%3Axlink%3D%22http%3A//www.w3.org/1999/xlink%22%3E%0A%20%3Cmetadata%3E%0A%20%20%3Crdf%3ARDF%20xmlns%3Acc%3D%22http%3A//creativecommons.org/ns%23%22%20xmlns%3Adc%3D%22http%3A//purl.org/dc/elements/1.1/%22%20xmlns%3Ardf%3D%22http%3A//www.w3.org/1999/02/22-rdf-syntax-ns%23%22%3E%0A%20%20%20%3Ccc%3AWork%3E%0A%20%20%20%20%3Cdc%3Atype%20rdf%3Aresource%3D%22http%3A//purl.org/dc/dcmitype/StillImage%22/%3E%0A%20%20%20%20%3Cdc%3Adate%3E2021-03-08T16%3A41%3A34.947284%3C/dc%3Adate%3E%0A%20%20%20%20%3Cdc%3Aformat%3Eimage/svg%2Bxml%3C/dc%3Aformat%3E%0A%20%20%20%20%3Cdc%3Acreator%3E%0A%20%20%20%20%20%3Ccc%3AAgent%3E%0A%20%20%20%20%20%20%3Cdc%3Atitle%3EMatplotlib%20v3.3.2%2C%20https%3A//matplotlib.org/%3C/dc%3Atitle%3E%0A%20%20%20%20%20%3C/cc%3AAgent%3E%0A%20%20%20%20%3C/dc%3Acreator%3E%0A%20%20%20%3C/cc%3AWork%3E%0A%20%20%3C/rdf%3ARDF%3E%0A%20%3C/metadata%3E%0A%20%3Cdefs%3E%0A%20%20%3Cstyle%20type%3D%22text/css%22%3E%2A%7Bstroke-linecap%3Abutt%3Bstroke-linejoin%3Around%3B%7D%3C/style%3E%0A%20%3C/defs%3E%0A%20%3Cg%20id%3D%22figure_1%22%3E%0A%20%20%3Cg%20id%3D%22patch_1%22%3E%0A%20%20%20%3Cpath%20d%3D%22M%200%20249.23625%20%0AL%20367.25%20249.23625%20%0AL%20367.25%200%20%0AL%200%200%20%0Az%0A%22%20style%3D%22fill%3Anone%3B%22/%3E%0A%20%20%3C/g%3E%0A%20%20%3Cg%20id%3D%22axes_1%22%3E%0A%20%20%20%3Cg%20id%3D%22patch_2%22%3E%0A%20%20%20%20%3Cpath%20d%3D%22M%2032.45%20232.558125%20%0AL%20367.25%20232.558125%20%0AL%20367.25%2015.118125%20%0AL%2032.45%2015.118125%20%0Az%0A%22%20style%3D%22fill%3A%23ffffff%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_3%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%2047.668182%20232.558125%20%0AL%2062.886364%20232.558125%20%0AL%2062.886364%20201.312238%20%0AL%2047.668182%20201.312238%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_4%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%2062.886364%20232.558125%20%0AL%2078.104545%20232.558125%20%0AL%2078.104545%20184.708774%20%0AL%2062.886364%20184.708774%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_5%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%2078.104545%20232.558125%20%0AL%2093.322727%20232.558125%20%0AL%2093.322727%2042.86029%20%0AL%2078.104545%2042.86029%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_6%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%2093.322727%20232.558125%20%0AL%20108.540909%20232.558125%20%0AL%20108.540909%20119.863753%20%0AL%2093.322727%20119.863753%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_7%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20108.540909%20232.558125%20%0AL%20123.759091%20232.558125%20%0AL%20123.759091%2025.472411%20%0AL%20108.540909%2025.472411%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_8%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20123.759091%20232.558125%20%0AL%20138.977273%20232.558125%20%0AL%20138.977273%20162.745138%20%0AL%20123.759091%20162.745138%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_9%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20138.977273%20232.558125%20%0AL%20154.195455%20232.558125%20%0AL%20154.195455%20123.262887%20%0AL%20138.977273%20123.262887%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_10%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20154.195455%20232.558125%20%0AL%20169.413636%20232.558125%20%0AL%20169.413636%20102.60661%20%0AL%20154.195455%20102.60661%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_11%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20169.413636%20232.558125%20%0AL%20184.631818%20232.558125%20%0AL%20184.631818%2082.99622%20%0AL%20169.413636%2082.99622%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_12%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20184.631818%20232.558125%20%0AL%20199.85%20232.558125%20%0AL%20199.85%20224.583233%20%0AL%20184.631818%20224.583233%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_13%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20199.85%20232.558125%20%0AL%20215.068182%20232.558125%20%0AL%20215.068182%20224.06029%20%0AL%20199.85%20224.06029%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_14%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20215.068182%20232.558125%20%0AL%20230.286364%20232.558125%20%0AL%20230.286364%20228.505311%20%0AL%20215.068182%20228.505311%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_15%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20230.286364%20232.558125%20%0AL%20245.504545%20232.558125%20%0AL%20245.504545%20228.766783%20%0AL%20230.286364%20228.766783%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_16%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20245.504545%20232.558125%20%0AL%20260.722727%20232.558125%20%0AL%20260.722727%20231.250766%20%0AL%20245.504545%20231.250766%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_17%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20260.722727%20232.558125%20%0AL%20275.940909%20232.558125%20%0AL%20275.940909%20231.642973%20%0AL%20260.722727%20231.642973%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_18%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20275.940909%20232.558125%20%0AL%20291.159091%20232.558125%20%0AL%20291.159091%20231.12003%20%0AL%20275.940909%20231.12003%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_19%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20291.159091%20232.558125%20%0AL%20306.377273%20232.558125%20%0AL%20306.377273%20232.165917%20%0AL%20291.159091%20232.165917%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_20%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20306.377273%20232.558125%20%0AL%20321.595455%20232.558125%20%0AL%20321.595455%20230.597086%20%0AL%20306.377273%20230.597086%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_21%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20321.595455%20232.558125%20%0AL%20336.813636%20232.558125%20%0AL%20336.813636%20231.512238%20%0AL%20321.595455%20231.512238%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_22%22%3E%0A%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20336.813636%20232.558125%20%0AL%20352.031818%20232.558125%20%0AL%20352.031818%20231.642973%20%0AL%20336.813636%20231.642973%20%0Az%0A%22%20style%3D%22fill%3A%231f77b4%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22matplotlib.axis_1%22%3E%0A%20%20%20%20%3Cg%20id%3D%22xtick_1%22%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_1%22%3E%0A%20%20%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%2047.318339%20232.558125%20%0AL%2047.318339%2015.118125%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23b0b0b0%3Bstroke-linecap%3Asquare%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_2%22%3E%0A%20%20%20%20%20%20%3Cdefs%3E%0A%20%20%20%20%20%20%20%3Cpath%20d%3D%22M%200%200%20%0AL%200%203.5%20%0A%22%20id%3D%22mf3083f3aad%22%20style%3D%22stroke%3A%23000000%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%20%20%20%3C/defs%3E%0A%20%20%20%20%20%20%3Cg%3E%0A%20%20%20%20%20%20%20%3Cuse%20style%3D%22stroke%3A%23000000%3Bstroke-width%3A0.8%3B%22%20x%3D%2247.318339%22%20xlink%3Ahref%3D%22%23mf3083f3aad%22%20y%3D%22232.558125%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22text_1%22%3E%0A%20%20%20%20%20%20%3C%21--%200%20--%3E%0A%20%20%20%20%20%20%3Cg%20transform%3D%22translate%2844.137089%20247.156563%29scale%280.1%20-0.1%29%22%3E%0A%20%20%20%20%20%20%20%3Cdefs%3E%0A%20%20%20%20%20%20%20%20%3Cpath%20d%3D%22M%2031.78125%2066.40625%20%0AQ%2024.171875%2066.40625%2020.328125%2058.90625%20%0AQ%2016.5%2051.421875%2016.5%2036.375%20%0AQ%2016.5%2021.390625%2020.328125%2013.890625%20%0AQ%2024.171875%206.390625%2031.78125%206.390625%20%0AQ%2039.453125%206.390625%2043.28125%2013.890625%20%0AQ%2047.125%2021.390625%2047.125%2036.375%20%0AQ%2047.125%2051.421875%2043.28125%2058.90625%20%0AQ%2039.453125%2066.40625%2031.78125%2066.40625%20%0Az%0AM%2031.78125%2074.21875%20%0AQ%2044.046875%2074.21875%2050.515625%2064.515625%20%0AQ%2056.984375%2054.828125%2056.984375%2036.375%20%0AQ%2056.984375%2017.96875%2050.515625%208.265625%20%0AQ%2044.046875%20-1.421875%2031.78125%20-1.421875%20%0AQ%2019.53125%20-1.421875%2013.0625%208.265625%20%0AQ%206.59375%2017.96875%206.59375%2036.375%20%0AQ%206.59375%2054.828125%2013.0625%2064.515625%20%0AQ%2019.53125%2074.21875%2031.78125%2074.21875%20%0Az%0A%22%20id%3D%22DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%20%3C/defs%3E%0A%20%20%20%20%20%20%20%3Cuse%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%3C/g%3E%0A%20%20%20%20%3Cg%20id%3D%22xtick_2%22%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_3%22%3E%0A%20%20%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20117.286991%20232.558125%20%0AL%20117.286991%2015.118125%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23b0b0b0%3Bstroke-linecap%3Asquare%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_4%22%3E%0A%20%20%20%20%20%20%3Cg%3E%0A%20%20%20%20%20%20%20%3Cuse%20style%3D%22stroke%3A%23000000%3Bstroke-width%3A0.8%3B%22%20x%3D%22117.286991%22%20xlink%3Ahref%3D%22%23mf3083f3aad%22%20y%3D%22232.558125%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22text_2%22%3E%0A%20%20%20%20%20%20%3C%21--%20200%20--%3E%0A%20%20%20%20%20%20%3Cg%20transform%3D%22translate%28107.743241%20247.156563%29scale%280.1%20-0.1%29%22%3E%0A%20%20%20%20%20%20%20%3Cdefs%3E%0A%20%20%20%20%20%20%20%20%3Cpath%20d%3D%22M%2019.1875%208.296875%20%0AL%2053.609375%208.296875%20%0AL%2053.609375%200%20%0AL%207.328125%200%20%0AL%207.328125%208.296875%20%0AQ%2012.9375%2014.109375%2022.625%2023.890625%20%0AQ%2032.328125%2033.6875%2034.8125%2036.53125%20%0AQ%2039.546875%2041.84375%2041.421875%2045.53125%20%0AQ%2043.3125%2049.21875%2043.3125%2052.78125%20%0AQ%2043.3125%2058.59375%2039.234375%2062.25%20%0AQ%2035.15625%2065.921875%2028.609375%2065.921875%20%0AQ%2023.96875%2065.921875%2018.8125%2064.3125%20%0AQ%2013.671875%2062.703125%207.8125%2059.421875%20%0AL%207.8125%2069.390625%20%0AQ%2013.765625%2071.78125%2018.9375%2073%20%0AQ%2024.125%2074.21875%2028.421875%2074.21875%20%0AQ%2039.75%2074.21875%2046.484375%2068.546875%20%0AQ%2053.21875%2062.890625%2053.21875%2053.421875%20%0AQ%2053.21875%2048.921875%2051.53125%2044.890625%20%0AQ%2049.859375%2040.875%2045.40625%2035.40625%20%0AQ%2044.1875%2033.984375%2037.640625%2027.21875%20%0AQ%2031.109375%2020.453125%2019.1875%208.296875%20%0Az%0A%22%20id%3D%22DejaVuSans-50%22/%3E%0A%20%20%20%20%20%20%20%3C/defs%3E%0A%20%20%20%20%20%20%20%3Cuse%20xlink%3Ahref%3D%22%23DejaVuSans-50%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%2263.623047%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%22127.246094%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%3C/g%3E%0A%20%20%20%20%3Cg%20id%3D%22xtick_3%22%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_5%22%3E%0A%20%20%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20187.255643%20232.558125%20%0AL%20187.255643%2015.118125%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23b0b0b0%3Bstroke-linecap%3Asquare%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_6%22%3E%0A%20%20%20%20%20%20%3Cg%3E%0A%20%20%20%20%20%20%20%3Cuse%20style%3D%22stroke%3A%23000000%3Bstroke-width%3A0.8%3B%22%20x%3D%22187.255643%22%20xlink%3Ahref%3D%22%23mf3083f3aad%22%20y%3D%22232.558125%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22text_3%22%3E%0A%20%20%20%20%20%20%3C%21--%20400%20--%3E%0A%20%20%20%20%20%20%3Cg%20transform%3D%22translate%28177.711893%20247.156563%29scale%280.1%20-0.1%29%22%3E%0A%20%20%20%20%20%20%20%3Cdefs%3E%0A%20%20%20%20%20%20%20%20%3Cpath%20d%3D%22M%2037.796875%2064.3125%20%0AL%2012.890625%2025.390625%20%0AL%2037.796875%2025.390625%20%0Az%0AM%2035.203125%2072.90625%20%0AL%2047.609375%2072.90625%20%0AL%2047.609375%2025.390625%20%0AL%2058.015625%2025.390625%20%0AL%2058.015625%2017.1875%20%0AL%2047.609375%2017.1875%20%0AL%2047.609375%200%20%0AL%2037.796875%200%20%0AL%2037.796875%2017.1875%20%0AL%204.890625%2017.1875%20%0AL%204.890625%2026.703125%20%0Az%0A%22%20id%3D%22DejaVuSans-52%22/%3E%0A%20%20%20%20%20%20%20%3C/defs%3E%0A%20%20%20%20%20%20%20%3Cuse%20xlink%3Ahref%3D%22%23DejaVuSans-52%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%2263.623047%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%22127.246094%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%3C/g%3E%0A%20%20%20%20%3Cg%20id%3D%22xtick_4%22%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_7%22%3E%0A%20%20%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20257.224295%20232.558125%20%0AL%20257.224295%2015.118125%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23b0b0b0%3Bstroke-linecap%3Asquare%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_8%22%3E%0A%20%20%20%20%20%20%3Cg%3E%0A%20%20%20%20%20%20%20%3Cuse%20style%3D%22stroke%3A%23000000%3Bstroke-width%3A0.8%3B%22%20x%3D%22257.224295%22%20xlink%3Ahref%3D%22%23mf3083f3aad%22%20y%3D%22232.558125%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22text_4%22%3E%0A%20%20%20%20%20%20%3C%21--%20600%20--%3E%0A%20%20%20%20%20%20%3Cg%20transform%3D%22translate%28247.680545%20247.156563%29scale%280.1%20-0.1%29%22%3E%0A%20%20%20%20%20%20%20%3Cdefs%3E%0A%20%20%20%20%20%20%20%20%3Cpath%20d%3D%22M%2033.015625%2040.375%20%0AQ%2026.375%2040.375%2022.484375%2035.828125%20%0AQ%2018.609375%2031.296875%2018.609375%2023.390625%20%0AQ%2018.609375%2015.53125%2022.484375%2010.953125%20%0AQ%2026.375%206.390625%2033.015625%206.390625%20%0AQ%2039.65625%206.390625%2043.53125%2010.953125%20%0AQ%2047.40625%2015.53125%2047.40625%2023.390625%20%0AQ%2047.40625%2031.296875%2043.53125%2035.828125%20%0AQ%2039.65625%2040.375%2033.015625%2040.375%20%0Az%0AM%2052.59375%2071.296875%20%0AL%2052.59375%2062.3125%20%0AQ%2048.875%2064.0625%2045.09375%2064.984375%20%0AQ%2041.3125%2065.921875%2037.59375%2065.921875%20%0AQ%2027.828125%2065.921875%2022.671875%2059.328125%20%0AQ%2017.53125%2052.734375%2016.796875%2039.40625%20%0AQ%2019.671875%2043.65625%2024.015625%2045.921875%20%0AQ%2028.375%2048.1875%2033.59375%2048.1875%20%0AQ%2044.578125%2048.1875%2050.953125%2041.515625%20%0AQ%2057.328125%2034.859375%2057.328125%2023.390625%20%0AQ%2057.328125%2012.15625%2050.6875%205.359375%20%0AQ%2044.046875%20-1.421875%2033.015625%20-1.421875%20%0AQ%2020.359375%20-1.421875%2013.671875%208.265625%20%0AQ%206.984375%2017.96875%206.984375%2036.375%20%0AQ%206.984375%2053.65625%2015.1875%2063.9375%20%0AQ%2023.390625%2074.21875%2037.203125%2074.21875%20%0AQ%2040.921875%2074.21875%2044.703125%2073.484375%20%0AQ%2048.484375%2072.75%2052.59375%2071.296875%20%0Az%0A%22%20id%3D%22DejaVuSans-54%22/%3E%0A%20%20%20%20%20%20%20%3C/defs%3E%0A%20%20%20%20%20%20%20%3Cuse%20xlink%3Ahref%3D%22%23DejaVuSans-54%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%2263.623047%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%22127.246094%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%3C/g%3E%0A%20%20%20%20%3Cg%20id%3D%22xtick_5%22%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_9%22%3E%0A%20%20%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%20327.192947%20232.558125%20%0AL%20327.192947%2015.118125%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23b0b0b0%3Bstroke-linecap%3Asquare%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_10%22%3E%0A%20%20%20%20%20%20%3Cg%3E%0A%20%20%20%20%20%20%20%3Cuse%20style%3D%22stroke%3A%23000000%3Bstroke-width%3A0.8%3B%22%20x%3D%22327.192947%22%20xlink%3Ahref%3D%22%23mf3083f3aad%22%20y%3D%22232.558125%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22text_5%22%3E%0A%20%20%20%20%20%20%3C%21--%20800%20--%3E%0A%20%20%20%20%20%20%3Cg%20transform%3D%22translate%28317.649197%20247.156563%29scale%280.1%20-0.1%29%22%3E%0A%20%20%20%20%20%20%20%3Cdefs%3E%0A%20%20%20%20%20%20%20%20%3Cpath%20d%3D%22M%2031.78125%2034.625%20%0AQ%2024.75%2034.625%2020.71875%2030.859375%20%0AQ%2016.703125%2027.09375%2016.703125%2020.515625%20%0AQ%2016.703125%2013.921875%2020.71875%2010.15625%20%0AQ%2024.75%206.390625%2031.78125%206.390625%20%0AQ%2038.8125%206.390625%2042.859375%2010.171875%20%0AQ%2046.921875%2013.96875%2046.921875%2020.515625%20%0AQ%2046.921875%2027.09375%2042.890625%2030.859375%20%0AQ%2038.875%2034.625%2031.78125%2034.625%20%0Az%0AM%2021.921875%2038.8125%20%0AQ%2015.578125%2040.375%2012.03125%2044.71875%20%0AQ%208.5%2049.078125%208.5%2055.328125%20%0AQ%208.5%2064.0625%2014.71875%2069.140625%20%0AQ%2020.953125%2074.21875%2031.78125%2074.21875%20%0AQ%2042.671875%2074.21875%2048.875%2069.140625%20%0AQ%2055.078125%2064.0625%2055.078125%2055.328125%20%0AQ%2055.078125%2049.078125%2051.53125%2044.71875%20%0AQ%2048%2040.375%2041.703125%2038.8125%20%0AQ%2048.828125%2037.15625%2052.796875%2032.3125%20%0AQ%2056.78125%2027.484375%2056.78125%2020.515625%20%0AQ%2056.78125%209.90625%2050.3125%204.234375%20%0AQ%2043.84375%20-1.421875%2031.78125%20-1.421875%20%0AQ%2019.734375%20-1.421875%2013.25%204.234375%20%0AQ%206.78125%209.90625%206.78125%2020.515625%20%0AQ%206.78125%2027.484375%2010.78125%2032.3125%20%0AQ%2014.796875%2037.15625%2021.921875%2038.8125%20%0Az%0AM%2018.3125%2054.390625%20%0AQ%2018.3125%2048.734375%2021.84375%2045.5625%20%0AQ%2025.390625%2042.390625%2031.78125%2042.390625%20%0AQ%2038.140625%2042.390625%2041.71875%2045.5625%20%0AQ%2045.3125%2048.734375%2045.3125%2054.390625%20%0AQ%2045.3125%2060.0625%2041.71875%2063.234375%20%0AQ%2038.140625%2066.40625%2031.78125%2066.40625%20%0AQ%2025.390625%2066.40625%2021.84375%2063.234375%20%0AQ%2018.3125%2060.0625%2018.3125%2054.390625%20%0Az%0A%22%20id%3D%22DejaVuSans-56%22/%3E%0A%20%20%20%20%20%20%20%3C/defs%3E%0A%20%20%20%20%20%20%20%3Cuse%20xlink%3Ahref%3D%22%23DejaVuSans-56%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%2263.623047%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%22127.246094%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%3C/g%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22matplotlib.axis_2%22%3E%0A%20%20%20%20%3Cg%20id%3D%22ytick_1%22%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_11%22%3E%0A%20%20%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%2032.45%20232.558125%20%0AL%20367.25%20232.558125%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23b0b0b0%3Bstroke-linecap%3Asquare%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_12%22%3E%0A%20%20%20%20%20%20%3Cdefs%3E%0A%20%20%20%20%20%20%20%3Cpath%20d%3D%22M%200%200%20%0AL%20-3.5%200%20%0A%22%20id%3D%22m316ac1d126%22%20style%3D%22stroke%3A%23000000%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%20%20%20%3C/defs%3E%0A%20%20%20%20%20%20%3Cg%3E%0A%20%20%20%20%20%20%20%3Cuse%20style%3D%22stroke%3A%23000000%3Bstroke-width%3A0.8%3B%22%20x%3D%2232.45%22%20xlink%3Ahref%3D%22%23m316ac1d126%22%20y%3D%22232.558125%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22text_6%22%3E%0A%20%20%20%20%20%20%3C%21--%200%20--%3E%0A%20%20%20%20%20%20%3Cg%20transform%3D%22translate%2819.0875%20236.357344%29scale%280.1%20-0.1%29%22%3E%0A%20%20%20%20%20%20%20%3Cuse%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%3C/g%3E%0A%20%20%20%20%3Cg%20id%3D%22ytick_2%22%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_13%22%3E%0A%20%20%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%2032.45%20206.410939%20%0AL%20367.25%20206.410939%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23b0b0b0%3Bstroke-linecap%3Asquare%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_14%22%3E%0A%20%20%20%20%20%20%3Cg%3E%0A%20%20%20%20%20%20%20%3Cuse%20style%3D%22stroke%3A%23000000%3Bstroke-width%3A0.8%3B%22%20x%3D%2232.45%22%20xlink%3Ahref%3D%22%23m316ac1d126%22%20y%3D%22206.410939%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22text_7%22%3E%0A%20%20%20%20%20%20%3C%21--%20200%20--%3E%0A%20%20%20%20%20%20%3Cg%20transform%3D%22translate%286.3625%20210.210158%29scale%280.1%20-0.1%29%22%3E%0A%20%20%20%20%20%20%20%3Cuse%20xlink%3Ahref%3D%22%23DejaVuSans-50%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%2263.623047%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%22127.246094%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%3C/g%3E%0A%20%20%20%20%3Cg%20id%3D%22ytick_3%22%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_15%22%3E%0A%20%20%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%2032.45%20180.263753%20%0AL%20367.25%20180.263753%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23b0b0b0%3Bstroke-linecap%3Asquare%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_16%22%3E%0A%20%20%20%20%20%20%3Cg%3E%0A%20%20%20%20%20%20%20%3Cuse%20style%3D%22stroke%3A%23000000%3Bstroke-width%3A0.8%3B%22%20x%3D%2232.45%22%20xlink%3Ahref%3D%22%23m316ac1d126%22%20y%3D%22180.263753%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22text_8%22%3E%0A%20%20%20%20%20%20%3C%21--%20400%20--%3E%0A%20%20%20%20%20%20%3Cg%20transform%3D%22translate%286.3625%20184.062971%29scale%280.1%20-0.1%29%22%3E%0A%20%20%20%20%20%20%20%3Cuse%20xlink%3Ahref%3D%22%23DejaVuSans-52%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%2263.623047%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%22127.246094%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%3C/g%3E%0A%20%20%20%20%3Cg%20id%3D%22ytick_4%22%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_17%22%3E%0A%20%20%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%2032.45%20154.116567%20%0AL%20367.25%20154.116567%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23b0b0b0%3Bstroke-linecap%3Asquare%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_18%22%3E%0A%20%20%20%20%20%20%3Cg%3E%0A%20%20%20%20%20%20%20%3Cuse%20style%3D%22stroke%3A%23000000%3Bstroke-width%3A0.8%3B%22%20x%3D%2232.45%22%20xlink%3Ahref%3D%22%23m316ac1d126%22%20y%3D%22154.116567%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22text_9%22%3E%0A%20%20%20%20%20%20%3C%21--%20600%20--%3E%0A%20%20%20%20%20%20%3Cg%20transform%3D%22translate%286.3625%20157.915785%29scale%280.1%20-0.1%29%22%3E%0A%20%20%20%20%20%20%20%3Cuse%20xlink%3Ahref%3D%22%23DejaVuSans-54%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%2263.623047%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%22127.246094%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%3C/g%3E%0A%20%20%20%20%3Cg%20id%3D%22ytick_5%22%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_19%22%3E%0A%20%20%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%2032.45%20127.96938%20%0AL%20367.25%20127.96938%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23b0b0b0%3Bstroke-linecap%3Asquare%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_20%22%3E%0A%20%20%20%20%20%20%3Cg%3E%0A%20%20%20%20%20%20%20%3Cuse%20style%3D%22stroke%3A%23000000%3Bstroke-width%3A0.8%3B%22%20x%3D%2232.45%22%20xlink%3Ahref%3D%22%23m316ac1d126%22%20y%3D%22127.96938%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22text_10%22%3E%0A%20%20%20%20%20%20%3C%21--%20800%20--%3E%0A%20%20%20%20%20%20%3Cg%20transform%3D%22translate%286.3625%20131.768599%29scale%280.1%20-0.1%29%22%3E%0A%20%20%20%20%20%20%20%3Cuse%20xlink%3Ahref%3D%22%23DejaVuSans-56%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%2263.623047%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%22127.246094%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%3C/g%3E%0A%20%20%20%20%3Cg%20id%3D%22ytick_6%22%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_21%22%3E%0A%20%20%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%2032.45%20101.822194%20%0AL%20367.25%20101.822194%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23b0b0b0%3Bstroke-linecap%3Asquare%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_22%22%3E%0A%20%20%20%20%20%20%3Cg%3E%0A%20%20%20%20%20%20%20%3Cuse%20style%3D%22stroke%3A%23000000%3Bstroke-width%3A0.8%3B%22%20x%3D%2232.45%22%20xlink%3Ahref%3D%22%23m316ac1d126%22%20y%3D%22101.822194%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22text_11%22%3E%0A%20%20%20%20%20%20%3C%21--%201000%20--%3E%0A%20%20%20%20%20%20%3Cg%20transform%3D%22translate%280%20105.621413%29scale%280.1%20-0.1%29%22%3E%0A%20%20%20%20%20%20%20%3Cdefs%3E%0A%20%20%20%20%20%20%20%20%3Cpath%20d%3D%22M%2012.40625%208.296875%20%0AL%2028.515625%208.296875%20%0AL%2028.515625%2063.921875%20%0AL%2010.984375%2060.40625%20%0AL%2010.984375%2069.390625%20%0AL%2028.421875%2072.90625%20%0AL%2038.28125%2072.90625%20%0AL%2038.28125%208.296875%20%0AL%2054.390625%208.296875%20%0AL%2054.390625%200%20%0AL%2012.40625%200%20%0Az%0A%22%20id%3D%22DejaVuSans-49%22/%3E%0A%20%20%20%20%20%20%20%3C/defs%3E%0A%20%20%20%20%20%20%20%3Cuse%20xlink%3Ahref%3D%22%23DejaVuSans-49%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%2263.623047%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%22127.246094%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%22190.869141%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%3C/g%3E%0A%20%20%20%20%3Cg%20id%3D%22ytick_7%22%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_23%22%3E%0A%20%20%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%2032.45%2075.675008%20%0AL%20367.25%2075.675008%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23b0b0b0%3Bstroke-linecap%3Asquare%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_24%22%3E%0A%20%20%20%20%20%20%3Cg%3E%0A%20%20%20%20%20%20%20%3Cuse%20style%3D%22stroke%3A%23000000%3Bstroke-width%3A0.8%3B%22%20x%3D%2232.45%22%20xlink%3Ahref%3D%22%23m316ac1d126%22%20y%3D%2275.675008%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22text_12%22%3E%0A%20%20%20%20%20%20%3C%21--%201200%20--%3E%0A%20%20%20%20%20%20%3Cg%20transform%3D%22translate%280%2079.474227%29scale%280.1%20-0.1%29%22%3E%0A%20%20%20%20%20%20%20%3Cuse%20xlink%3Ahref%3D%22%23DejaVuSans-49%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%2263.623047%22%20xlink%3Ahref%3D%22%23DejaVuSans-50%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%22127.246094%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%22190.869141%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%3C/g%3E%0A%20%20%20%20%3Cg%20id%3D%22ytick_8%22%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_25%22%3E%0A%20%20%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%2032.45%2049.527822%20%0AL%20367.25%2049.527822%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23b0b0b0%3Bstroke-linecap%3Asquare%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_26%22%3E%0A%20%20%20%20%20%20%3Cg%3E%0A%20%20%20%20%20%20%20%3Cuse%20style%3D%22stroke%3A%23000000%3Bstroke-width%3A0.8%3B%22%20x%3D%2232.45%22%20xlink%3Ahref%3D%22%23m316ac1d126%22%20y%3D%2249.527822%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22text_13%22%3E%0A%20%20%20%20%20%20%3C%21--%201400%20--%3E%0A%20%20%20%20%20%20%3Cg%20transform%3D%22translate%280%2053.327041%29scale%280.1%20-0.1%29%22%3E%0A%20%20%20%20%20%20%20%3Cuse%20xlink%3Ahref%3D%22%23DejaVuSans-49%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%2263.623047%22%20xlink%3Ahref%3D%22%23DejaVuSans-52%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%22127.246094%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%22190.869141%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%3C/g%3E%0A%20%20%20%20%3Cg%20id%3D%22ytick_9%22%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_27%22%3E%0A%20%20%20%20%20%20%3Cpath%20clip-path%3D%22url%28%23pa4934c87f0%29%22%20d%3D%22M%2032.45%2023.380636%20%0AL%20367.25%2023.380636%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23b0b0b0%3Bstroke-linecap%3Asquare%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22line2d_28%22%3E%0A%20%20%20%20%20%20%3Cg%3E%0A%20%20%20%20%20%20%20%3Cuse%20style%3D%22stroke%3A%23000000%3Bstroke-width%3A0.8%3B%22%20x%3D%2232.45%22%20xlink%3Ahref%3D%22%23m316ac1d126%22%20y%3D%2223.380636%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3Cg%20id%3D%22text_14%22%3E%0A%20%20%20%20%20%20%3C%21--%201600%20--%3E%0A%20%20%20%20%20%20%3Cg%20transform%3D%22translate%280%2027.179855%29scale%280.1%20-0.1%29%22%3E%0A%20%20%20%20%20%20%20%3Cuse%20xlink%3Ahref%3D%22%23DejaVuSans-49%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%2263.623047%22%20xlink%3Ahref%3D%22%23DejaVuSans-54%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%22127.246094%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%20%3Cuse%20x%3D%22190.869141%22%20xlink%3Ahref%3D%22%23DejaVuSans-48%22/%3E%0A%20%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%20%3C/g%3E%0A%20%20%20%20%3C/g%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_23%22%3E%0A%20%20%20%20%3Cpath%20d%3D%22M%2032.45%20232.558125%20%0AL%2032.45%2015.118125%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23000000%3Bstroke-linecap%3Asquare%3Bstroke-linejoin%3Amiter%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_24%22%3E%0A%20%20%20%20%3Cpath%20d%3D%22M%20367.25%20232.558125%20%0AL%20367.25%2015.118125%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23000000%3Bstroke-linecap%3Asquare%3Bstroke-linejoin%3Amiter%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_25%22%3E%0A%20%20%20%20%3Cpath%20d%3D%22M%2032.45%20232.558125%20%0AL%20367.25%20232.558125%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23000000%3Bstroke-linecap%3Asquare%3Bstroke-linejoin%3Amiter%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22patch_26%22%3E%0A%20%20%20%20%3Cpath%20d%3D%22M%2032.45%2015.118125%20%0AL%20367.25%2015.118125%20%0A%22%20style%3D%22fill%3Anone%3Bstroke%3A%23000000%3Bstroke-linecap%3Asquare%3Bstroke-linejoin%3Amiter%3Bstroke-width%3A0.8%3B%22/%3E%0A%20%20%20%3C/g%3E%0A%20%20%20%3Cg%20id%3D%22text_15%22%3E%0A%20%20%20%20%3C%21--%20pdays%20--%3E%0A%20%20%20%20%3Cg%20transform%3D%22translate%28181.878125%209.118125%29scale%280.12%20-0.12%29%22%3E%0A%20%20%20%20%20%3Cdefs%3E%0A%20%20%20%20%20%20%3Cpath%20d%3D%22M%2018.109375%208.203125%20%0AL%2018.109375%20-20.796875%20%0AL%209.078125%20-20.796875%20%0AL%209.078125%2054.6875%20%0AL%2018.109375%2054.6875%20%0AL%2018.109375%2046.390625%20%0AQ%2020.953125%2051.265625%2025.265625%2053.625%20%0AQ%2029.59375%2056%2035.59375%2056%20%0AQ%2045.5625%2056%2051.78125%2048.09375%20%0AQ%2058.015625%2040.1875%2058.015625%2027.296875%20%0AQ%2058.015625%2014.40625%2051.78125%206.484375%20%0AQ%2045.5625%20-1.421875%2035.59375%20-1.421875%20%0AQ%2029.59375%20-1.421875%2025.265625%200.953125%20%0AQ%2020.953125%203.328125%2018.109375%208.203125%20%0Az%0AM%2048.6875%2027.296875%20%0AQ%2048.6875%2037.203125%2044.609375%2042.84375%20%0AQ%2040.53125%2048.484375%2033.40625%2048.484375%20%0AQ%2026.265625%2048.484375%2022.1875%2042.84375%20%0AQ%2018.109375%2037.203125%2018.109375%2027.296875%20%0AQ%2018.109375%2017.390625%2022.1875%2011.75%20%0AQ%2026.265625%206.109375%2033.40625%206.109375%20%0AQ%2040.53125%206.109375%2044.609375%2011.75%20%0AQ%2048.6875%2017.390625%2048.6875%2027.296875%20%0Az%0A%22%20id%3D%22DejaVuSans-112%22/%3E%0A%20%20%20%20%20%20%3Cpath%20d%3D%22M%2045.40625%2046.390625%20%0AL%2045.40625%2075.984375%20%0AL%2054.390625%2075.984375%20%0AL%2054.390625%200%20%0AL%2045.40625%200%20%0AL%2045.40625%208.203125%20%0AQ%2042.578125%203.328125%2038.25%200.953125%20%0AQ%2033.9375%20-1.421875%2027.875%20-1.421875%20%0AQ%2017.96875%20-1.421875%2011.734375%206.484375%20%0AQ%205.515625%2014.40625%205.515625%2027.296875%20%0AQ%205.515625%2040.1875%2011.734375%2048.09375%20%0AQ%2017.96875%2056%2027.875%2056%20%0AQ%2033.9375%2056%2038.25%2053.625%20%0AQ%2042.578125%2051.265625%2045.40625%2046.390625%20%0Az%0AM%2014.796875%2027.296875%20%0AQ%2014.796875%2017.390625%2018.875%2011.75%20%0AQ%2022.953125%206.109375%2030.078125%206.109375%20%0AQ%2037.203125%206.109375%2041.296875%2011.75%20%0AQ%2045.40625%2017.390625%2045.40625%2027.296875%20%0AQ%2045.40625%2037.203125%2041.296875%2042.84375%20%0AQ%2037.203125%2048.484375%2030.078125%2048.484375%20%0AQ%2022.953125%2048.484375%2018.875%2042.84375%20%0AQ%2014.796875%2037.203125%2014.796875%2027.296875%20%0Az%0A%22%20id%3D%22DejaVuSans-100%22/%3E%0A%20%20%20%20%20%20%3Cpath%20d%3D%22M%2034.28125%2027.484375%20%0AQ%2023.390625%2027.484375%2019.1875%2025%20%0AQ%2014.984375%2022.515625%2014.984375%2016.5%20%0AQ%2014.984375%2011.71875%2018.140625%208.90625%20%0AQ%2021.296875%206.109375%2026.703125%206.109375%20%0AQ%2034.1875%206.109375%2038.703125%2011.40625%20%0AQ%2043.21875%2016.703125%2043.21875%2025.484375%20%0AL%2043.21875%2027.484375%20%0Az%0AM%2052.203125%2031.203125%20%0AL%2052.203125%200%20%0AL%2043.21875%200%20%0AL%2043.21875%208.296875%20%0AQ%2040.140625%203.328125%2035.546875%200.953125%20%0AQ%2030.953125%20-1.421875%2024.3125%20-1.421875%20%0AQ%2015.921875%20-1.421875%2010.953125%203.296875%20%0AQ%206%208.015625%206%2015.921875%20%0AQ%206%2025.140625%2012.171875%2029.828125%20%0AQ%2018.359375%2034.515625%2030.609375%2034.515625%20%0AL%2043.21875%2034.515625%20%0AL%2043.21875%2035.40625%20%0AQ%2043.21875%2041.609375%2039.140625%2045%20%0AQ%2035.0625%2048.390625%2027.6875%2048.390625%20%0AQ%2023%2048.390625%2018.546875%2047.265625%20%0AQ%2014.109375%2046.140625%2010.015625%2043.890625%20%0AL%2010.015625%2052.203125%20%0AQ%2014.9375%2054.109375%2019.578125%2055.046875%20%0AQ%2024.21875%2056%2028.609375%2056%20%0AQ%2040.484375%2056%2046.34375%2049.84375%20%0AQ%2052.203125%2043.703125%2052.203125%2031.203125%20%0Az%0A%22%20id%3D%22DejaVuSans-97%22/%3E%0A%20%20%20%20%20%20%3Cpath%20d%3D%22M%2032.171875%20-5.078125%20%0AQ%2028.375%20-14.84375%2024.75%20-17.8125%20%0AQ%2021.140625%20-20.796875%2015.09375%20-20.796875%20%0AL%207.90625%20-20.796875%20%0AL%207.90625%20-13.28125%20%0AL%2013.1875%20-13.28125%20%0AQ%2016.890625%20-13.28125%2018.9375%20-11.515625%20%0AQ%2021%20-9.765625%2023.484375%20-3.21875%20%0AL%2025.09375%200.875%20%0AL%202.984375%2054.6875%20%0AL%2012.5%2054.6875%20%0AL%2029.59375%2011.921875%20%0AL%2046.6875%2054.6875%20%0AL%2056.203125%2054.6875%20%0Az%0A%22%20id%3D%22DejaVuSans-121%22/%3E%0A%20%20%20%20%20%20%3Cpath%20d%3D%22M%2044.28125%2053.078125%20%0AL%2044.28125%2044.578125%20%0AQ%2040.484375%2046.53125%2036.375%2047.5%20%0AQ%2032.28125%2048.484375%2027.875%2048.484375%20%0AQ%2021.1875%2048.484375%2017.84375%2046.4375%20%0AQ%2014.5%2044.390625%2014.5%2040.28125%20%0AQ%2014.5%2037.15625%2016.890625%2035.375%20%0AQ%2019.28125%2033.59375%2026.515625%2031.984375%20%0AL%2029.59375%2031.296875%20%0AQ%2039.15625%2029.25%2043.1875%2025.515625%20%0AQ%2047.21875%2021.78125%2047.21875%2015.09375%20%0AQ%2047.21875%207.46875%2041.1875%203.015625%20%0AQ%2035.15625%20-1.421875%2024.609375%20-1.421875%20%0AQ%2020.21875%20-1.421875%2015.453125%20-0.5625%20%0AQ%2010.6875%200.296875%205.421875%202%20%0AL%205.421875%2011.28125%20%0AQ%2010.40625%208.6875%2015.234375%207.390625%20%0AQ%2020.0625%206.109375%2024.8125%206.109375%20%0AQ%2031.15625%206.109375%2034.5625%208.28125%20%0AQ%2037.984375%2010.453125%2037.984375%2014.40625%20%0AQ%2037.984375%2018.0625%2035.515625%2020.015625%20%0AQ%2033.0625%2021.96875%2024.703125%2023.78125%20%0AL%2021.578125%2024.515625%20%0AQ%2013.234375%2026.265625%209.515625%2029.90625%20%0AQ%205.8125%2033.546875%205.8125%2039.890625%20%0AQ%205.8125%2047.609375%2011.28125%2051.796875%20%0AQ%2016.75%2056%2026.8125%2056%20%0AQ%2031.78125%2056%2036.171875%2055.265625%20%0AQ%2040.578125%2054.546875%2044.28125%2053.078125%20%0Az%0A%22%20id%3D%22DejaVuSans-115%22/%3E%0A%20%20%20%20%20%3C/defs%3E%0A%20%20%20%20%20%3Cuse%20xlink%3Ahref%3D%22%23DejaVuSans-112%22/%3E%0A%20%20%20%20%20%3Cuse%20x%3D%2263.476562%22%20xlink%3Ahref%3D%22%23DejaVuSans-100%22/%3E%0A%20%20%20%20%20%3Cuse%20x%3D%22126.953125%22%20xlink%3Ahref%3D%22%23DejaVuSans-97%22/%3E%0A%20%20%20%20%20%3Cuse%20x%3D%22188.232422%22%20xlink%3Ahref%3D%22%23DejaVuSans-121%22/%3E%0A%20%20%20%20%20%3Cuse%20x%3D%22247.412109%22%20xlink%3Ahref%3D%22%23DejaVuSans-115%22/%3E%0A%20%20%20%20%3C/g%3E%0A%20%20%20%3C/g%3E%0A%20%20%3C/g%3E%0A%20%3C/g%3E%0A%20%3Cdefs%3E%0A%20%20%3CclipPath%20id%3D%22pa4934c87f0%22%3E%0A%20%20%20%3Crect%20height%3D%22217.44%22%20width%3D%22334.8%22%20x%3D%2232.45%22%20y%3D%2215.118125%22/%3E%0A%20%20%3C/clipPath%3E%0A%20%3C/defs%3E%0A%3C/svg%3E%0A\"><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>224.577692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115.344035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>133.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>327.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>871.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>"
      ],
      "text/plain": [
       "<jutils.html.HBox at 0x2269bcdb5b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdays_contacted = data.pdays[data.pdays != -1].to_frame()\n",
    "pdays_contacted.hist(bins=20)\n",
    "\n",
    "std_ = pdays_contacted.describe().loc['std']\n",
    "\n",
    "HBox( [ Plot(), pdays_contacted.describe() ], css = { 'height': '20em', 'column-gap': '1em' } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loan', 'month', 'marital', 'default', 'day', 'poutcome', 'education', 'job', 'contact', 'housing']\n"
     ]
    }
   ],
   "source": [
    "print(categorical)\n",
    "\n",
    "# The number of attributes you need to pass after `config` depends on how many data arguments you pass to the Agent()\n",
    "def preprocessing(config: dict, x, y):\n",
    "    x = x.copy()  # to prevent change of values in the initial dataset\n",
    "    try:\n",
    "        if config['one_hot_encode']:        \n",
    "            x = pd.get_dummies(x, columns=categorical)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        ##### Modell recall as an inverse on the pdays (number of days that passed by after the client was last contacted)\n",
    "        if config['new_features']:\n",
    "            x[\"recall\"] = x.pdays.apply(lambda el: 0 if (el == -1) or (el == 0) else 1 / el)\n",
    "            x['attention'] = x.duration * x.campaign\n",
    "            x['recognition'] = x.attention * x.recall\n",
    "            x['importance'] = x.recognition * x.balance\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return x, y\n",
    "\n",
    "\n",
    "build_model_xgb = lambda x: XGBClassifier(**x, verbosity=0)\n",
    "\n",
    "# Not\n",
    "agnt = Agent(X, y, build_model=build_model_xgb, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(config: dict, df):\n",
    "    y = df.y\n",
    "    x = df.iloc[:, :-1]\n",
    "        \n",
    "    try:\n",
    "        if config['one_hot_encode']:        \n",
    "            x = pd.get_dummies(x, columns=categorical)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    try:\n",
    "        ##### Modell recall as an inverse on the pdays (number of days that passed by after the client was last contacted)\n",
    "        if config['new_features']:\n",
    "            x[\"recall\"] = x.pdays.apply(lambda el: 0 if (el == -1) or (el == 0) else 1 / el)\n",
    "            x['attention'] = x.duration * x.campaign\n",
    "            x['recognition'] = x.attention * x.recall\n",
    "            x['importance'] = x.recognition * x.balance\n",
    "    except KeyError:\n",
    "        pass\n",
    "    return x, y\n",
    "\n",
    "agnt = Agent(df, build_model=build_model_xgb, preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base case: all preprocessing keys are set to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 40689 samples.\n",
      "Training session: 1  | loss: 9.2691e-01 | val_loss: 9.0292e-01\n",
      "Training session: 2  | loss: 9.2489e-01 | val_loss: 9.1128e-01\n",
      "Training session: 3  | loss: 9.2354e-01 | val_loss: 9.0772e-01\n",
      "Training session: 4  | loss: 9.2467e-01 | val_loss: 9.0526e-01\n",
      "Training session: 5  | loss: 9.2440e-01 | val_loss: 9.0771e-01\n",
      "--------------------------------------------------------------\n",
      "\u001b[36mAverage values:      |       9.2488e-01 |           9.0698e-01\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "config_xgb = {\n",
    "    'n_estimators': 128, 'subsample': 1.0, 'learning_rate': 0.2, \n",
    "    'min_child_weight': 1, 'max_depth': 4, 'gamma': 0.9, 'colsample_bytree': 0.6,\n",
    "    'one_hot_encode': False,\n",
    "    'new_features': False,\n",
    "}\n",
    "\n",
    "bias, var, model = agnt.eval_model_cv(config_xgb, training_mode='test', print_sessions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GridSearch for Hyperparameter: one_hot_encode, new_features\n",
      "Current configuration: {'n_estimators': 128, 'subsample': 1.000000e+00, 'learning_rate': 2.000000e-01, 'min_child_weight': 1, 'max_depth': 4, 'gamma': 9.000000e-01, 'colsample_bytree': 6.000000e-01, 'one_hot_encode': False, 'new_features': False}\n",
      " Variance: -9.073705e-01, Bias: -9.257539e-01, HyperParams: {'one_hot_encode': 1, 'new_features': 1}, Time: 0:00:07\n",
      " Variance: -9.073705e-01, Bias: -9.252931e-01, HyperParams: {'one_hot_encode': 1, 'new_features': 0}, Time: 0:00:07\n",
      " Variance: -9.074197e-01, Bias: -9.259628e-01, HyperParams: {'one_hot_encode': 0, 'new_features': 1}, Time: 0:00:04\n",
      " Variance: -9.075426e-01, Bias: -9.242854e-01, HyperParams: {'one_hot_encode': 0, 'new_features': 0}, Time: 0:00:04\n",
      "Max. Variance: -9.075426e-01, Best HyperParams: {'one_hot_encode': 0, 'new_features': 0}, Time: 0:00:24\n",
      "\n",
      "Best config: {'n_estimators': 128, 'subsample': 1.0, 'learning_rate': 0.2, 'min_child_weight': 1, 'max_depth': 4, 'gamma': 0.9, 'colsample_bytree': 0.6, 'one_hot_encode': 0, 'new_features': 0}\n"
     ]
    }
   ],
   "source": [
    "from dope.method import Mode\n",
    "\n",
    "params = [\n",
    "    Mode('one_hot_encode', [1, 0]),\n",
    "    Mode('new_features',   [1, 0]),\n",
    "]\n",
    "\n",
    "var, conf, model = agnt.scan('grid', parameter_space=params, config=config_xgb, strategy='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluation\"></a>\n",
    "## 2.4 Define [custom evaluation](#content) methods. However you should keep in mind that you need to pass the data you want to use for evaluation too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=RND_SEED)\n",
    "\n",
    "def eval_xgb(config, cv=5, scoring='roc_auc'):\n",
    "    model = build_model_xgb(config)\n",
    "    cv_results = cross_validate(model, x_train, y_train, cv=cv, n_jobs=-1, scoring=scoring, return_train_score=True)\n",
    "    \n",
    "    # Here we use the worst loss of all partitions for example\n",
    "    return -(cv_results['train_score'].min()), -(cv_results['test_score'].min()), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomSearch for Hyperparameter: one_hot_encode, new_features\n",
      "Current configuration: {'one_hot_encode': 1, 'new_features': 1}\n",
      " Variance: -9.207003e-01, Bias: -9.798107e-01, HyperParams: {'one_hot_encode': 0, 'new_features': 0}, Time: 0:00:05\n",
      " Variance: -9.207003e-01, Bias: -9.798107e-01, HyperParams: {'one_hot_encode': 1, 'new_features': 1}, Time: 0:00:05\n",
      "Min. Variance: -9.207003e-01, Best HyperParams: {'one_hot_encode': 1, 'new_features': 1}, Time: 0:00:11\n",
      "\n",
      "Best config: {'one_hot_encode': 1, 'new_features': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.9207003339269976, {'one_hot_encode': 1, 'new_features': 1})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var, conf, model = agnt_xgb.scan('random', parameter_space=params, eval_func=eval_xgb, random_samples=2)\n",
    "var, conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Customize\"></a>\n",
    "##  2.5 [Customize](#content) your scan: \n",
    "* maximize or minimize target value with `strategy` argument\n",
    "* select target value for optimization with `target`: {'bias', 'variance'}\n",
    "* different metrics with `scoring` argument for model evaluation (sklearn models).\n",
    "* `early_preprocessing` argument is used to specify when to use preprocessing on data. \n",
    "   `True` executes preprocessing function before data splitting in complementary partitions for cross validation, `False` - after, just before fit_func \n",
    "* customize outuput with `output_names` argument. See more in scan docstring\n",
    "\n",
    "\n",
    "<font size=3>Agent uses default scoring parameter for particular model. This is `accurasy` for xgb, for example.<br></br>\n",
    "    See available metrics for sklearn models [here](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules).</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 40689 samples, testing on 4522 samples.\n",
      "\u001b[36mTraining session: 1  | roc_auc: 1.0066e+04 | val_roc_auc: 1.5606e+03**\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "res, model = agnt_xgb.train_model_on(config_xgb, training_mode='test', scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomSearch for Hyperparameter: one_hot_encode, new_features\n",
      "Current config: {'one_hot_encode': 1, 'new_features': 1}\n",
      " neg Val Acc: -3.303422e+03, neg Acc: 4.231432e+02, HyperParams: {'one_hot_encode': 0, 'new_features': 1}, Time: 0:00:06\n",
      " neg Val Acc: -3.188046e+03, neg Acc: 3.102644e+02, HyperParams: {'one_hot_encode': 1, 'new_features': 1}, Time: 0:00:06\n",
      "Max. Variance: -3.303422e+03, Best HyperParams: {'one_hot_encode': 1, 'new_features': 1}, Time: 0:00:12\n",
      "\n",
      "Best config: {'one_hot_encode': 1, 'new_features': 1}\n"
     ]
    }
   ],
   "source": [
    "out_names = {\n",
    "    \"mode_var\": \"Hyperparameter\",\n",
    "    \"pivot_point\": \"Current config\",\n",
    "    \"refer_val\": \"neg Acc\",\n",
    "    \"target_val\": \"neg Val Acc\",\n",
    "    \"mode_arg\": \"HyperParams\",\n",
    "    \"minimum\": \"Best config\",\n",
    "}\n",
    "\n",
    "_, _, _ = agnt_xgb.scan('random', parameter_space=params, random_samples=2, \n",
    "                        scoring='roc_auc', strategy='max', \n",
    "                        output_names=out_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"examples\"></a>\n",
    "# [3. Examples](#content)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets say we want to train model on resampled data and test on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36168 train samples\n",
      "9043 test samples\n",
      "#Yes: 31942 | #No: 31942\n"
     ]
    }
   ],
   "source": [
    "# Instanciate Agent as a data_container object to split the data\n",
    "data_container = Agent(X, y, val_split=0.2, random_seed=RND_SEED)\n",
    "\n",
    "# Prepare original data\n",
    "train_xy = data_container.train_xy\n",
    "test_xy = data_container.test_xy\n",
    "\n",
    "print(f'{train_xy[0].shape[0]} train samples')\n",
    "print(f'{test_xy[0].shape[0]} test samples')\n",
    "\n",
    "# Resampling\n",
    "smote = SMOTE(random_state=RND_SEED)\n",
    "X_res, y_res = smote.fit_resample(*train_xy)\n",
    "\n",
    "print(f\"#Yes: {sum(y_res)} | #No: {sum(~y_res+2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "def build_model_xgb(config):\n",
    "    return XGBClassifier(**config, random_state=RND_SEED)\n",
    "\n",
    "agnt = Agent(*train_xy, build_model=build_model_xgb, random_seed=RND_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 32551 samples, testing on 9043 samples.\n",
      "\u001b[36mTraining session: 1  | loss: 9.3358e-01 | val_loss: 8.9981e-01**\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "config = {'n_estimators':100, 'subsample': 1.0, 'learning_rate': 0.2, 'min_child_weight': 10, \n",
    "          'max_depth': 6, 'gamma': 1, 'colsample_bytree': 0.6, 'eval_metric': 'logloss'}\n",
    "\n",
    "res, model = agnt.train_model_on(config, validation_mode='full', test_data=test_xy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create X with one-hot-encoded categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63884, 81)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res_enc = pd.get_dummies(X_res, columns=categorical)\n",
    "X_res_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biva.utils.plotters import plot_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=['acc']\n",
    "\n",
    "def build_model_keras(config):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(config['denseLayer1'], activation=config['actFuncL1'], input_dim=X_res_enc.shape[1]))\n",
    "    model.add(Dense(config['denseLayer2'], activation=config['actFuncL2']))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation=config['actFuncLast']))\n",
    "    \n",
    "    lm = tf.keras.optimizers.Adadelta(lr=config['lr'])\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=lm, metrics=metrics)\n",
    "    return model\n",
    "\n",
    "config_keras = {\n",
    "    'denseLayer1': 256, 'actFuncL1': 'elu',\n",
    "    'denseLayer2': 256, 'actFuncL2': 'elu',\n",
    "    'actFuncLast': 'sigmoid', \n",
    "    'epochs':5, 'batch_size': 32,\n",
    "    'lr': 0.01, 'beta_1': 0.85}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.0005, patience=4)]\n",
    "agent = Agent(X_res_enc, y_res, build_model=build_model_keras, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 57495 samples, testing on 6389 samples.\n",
      "\u001b[36mTraining session: 1  | loss: 3.1870e-01 | val_loss: 3.2270e-01**\n",
      "\u001b[0m\u001b[36mTraining session: 2  | loss: 3.1848e-01 | val_loss: 3.2197e-01**\n",
      "\u001b[0mTraining session: 3  | loss: 3.1871e-01 | val_loss: 3.2293e-01\n",
      "--------------------------------------------------------------\n",
      "Average values:      |       3.1863e-01 |           3.2253e-01\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log, model = agent.train_model_on(config_keras, n_trainings=3, epochs=1000, batch_size=256)\n",
    "plot_epochs(log, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can also change the metric output name in output and criterion for the training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "log, model = agent.train_model_on(config_keras, n_trainings=4, \n",
    "                                  epochs=120, batch_size=512, \n",
    "                                  criterion='variance', metric_name='mse')\n",
    "plot_epochs(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = [Mode(f'denseLayer{i}', [32, 64, 128, 256]) for i in range(1, 3)]\n",
    "\n",
    "var, bconf, model = agent.scan('acs', neurons, config_keras, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "bconf = {'denseLayer1': 256, 'actFuncL1': 'relu', 'denseLayer2': 64, 'actFuncL2': 'relu', \n",
    "         'actFuncLast': 'sigmoid', 'lr': 0.09539879737836925, 'beta_1': 0.85}\n",
    "\n",
    "log, model = agent.train_model_on(bconf, validation_mode='test', epochs=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epochs(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epochs(log, ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def build_model_logregr(config):\n",
    "    # Notice that I don't use random_state=RND_SEED now.\n",
    "    return LogisticRegression(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agnt_logr = Agent(X_res, y_res, build_model=build_model_logregr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_logregr = dict(C=0.001, penalty='l2', random_state=1)\n",
    "agnt_logr.train_model_on(config_logregr, print_sessions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biva.utils import dict_to_ModeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"C\":       np.logspace(-3,3,7), \n",
    "          \"penalty\": ['l2', 'None']}\n",
    "\n",
    "params = dict_to_ModeList(params)\n",
    "print(format_parameter_space(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var, bconf_logregr, logreger, = agnt_logr.scan('random', params, random_samples=5)\n",
    "bconf_logregr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring parameter can be passed for any sklear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "res, model = agnt_logr.train_model_on(bconf_logregr, scoring='adjusted_rand_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Unbalanced_data\"></a>\n",
    "## [Unbalanced data](#content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to change input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_keras(config):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(config['denseLayer1'], activation=config['actFuncL1'], input_dim=X.shape[1]))\n",
    "    model.add(Dense(config['denseLayer2'], activation=config['actFuncL2']))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation=config['actFuncLast']))\n",
    "    lm = tf.keras.optimizers.Adadelta(lr=config['lr'])\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=lm, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=3)]\n",
    "agent = Agent(X, y, build_model=build_model_keras, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bconf = {'denseLayer1': 256, 'actFuncL1': 'relu', 'denseLayer2': 64, 'actFuncL2': 'relu', \n",
    "         'actFuncLast': 'sigmoid', 'epochs': 5, 'lr': 0.09539879737836925, 'beta_1': 0.85}\n",
    "\n",
    "log, model = agent.train_model_on(bconf, n_trainings=3, validation_mode='test', criterion='variance', epochs=500, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biva.utils.metrics import confusion_matrix_by_threshold\n",
    "from biva.utils.plotters import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default confusion metrics (thresh=0.5)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(agent.x_test)\n",
    "y_true = agent.y_test\n",
    "cmat = confusion_matrix_by_threshold(y_true, y_pred)\n",
    "plot_confusion_matrix(cmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Context**\n",
    "\n",
    "* **True positive** - client subscribed a term deposit just as predicted. Income. (**maximize**)\n",
    "* **False positive** - client did not subscribe to a term deposit just as predicted, so we might as well haven't wasted our time.(**maximize**)\n",
    "* **False negative** - predicted that client *would not* subscribe, but he actually would! Income waste. (**minimize**)\n",
    "* **False positive** - predicted that client *would* subscribe, but he didn't. Time waste.\n",
    "\n",
    "So taken into account our group sizes and that we want to maximize icome and minimise time wasted we conclude that **tp**, **tn** and **fn** are of key importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biva.utils.metrics import class_metrics, class_metrics_by_threshold, get_best_thres\n",
    "from biva.utils.plotters import plot_metrics_per_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbt = class_metrics_by_threshold(y_true, y_pred)\n",
    "mbt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr, metric = get_best_thres(mbt, 'matthews_corrcoef')\n",
    "thr, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(agent.x_test)\n",
    "y_true = agent.y_test\n",
    "cmat = confusion_matrix_by_threshold(y_true, y_pred, thr)\n",
    "plot_confusion_matrix(cmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_metrics_per_threshold(y_true, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_xgb(config):\n",
    "    model = XGBClassifier(**config)\n",
    "    return model\n",
    "\n",
    "agnt_xgb = Agent(X, y, build_model=build_model_xgb, splitter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_xgb = {\n",
    "    'max_depth':20,\n",
    "    'n_estimators':500,\n",
    "    'subsample': 1.0,\n",
    "    'learning_rate': 0.3,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 2,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'eval_metric': 'logloss'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "agnt_xgb.train_model_on(config_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can also evaluate model performance by means of cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bias, var, model = agnt_xgb.eval_model_cv_sklearn(config_xgb)\n",
    "bias, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    Mode('n_estimators',     values=[100, 500, 1000]),\n",
    "    Mode('max_depth',        values=np.arange(5, 21, 5)),\n",
    "    Mode('learning_rate',    values=[0.001, 1.0], mode_optimizer='bayessearch', init_points=5, n_trials=20),\n",
    "    Mode('gamma',            values=[0.5, 1, 2, 5, 10, 20]),\n",
    "    Mode('min_child_weight', values=[1, 5, 10, 20, 40, 60]),\n",
    "    Mode('subsample',        values=[0.6, 0.7, 0.8, 1.0]),\n",
    "    Mode('colsample_bytree', values=[0.6, 0.8, 1.0]),\n",
    "    Mode('subsample',        values=[0.8, 1.0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format_parameter_space(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?Agent().scan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
